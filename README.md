ASL Sign Language Classifier with MediaPipe & Scikit-learn

This project uses real-time webcam input and machine learning to detect and classify American Sign Language (ASL) hand signs. It leverages MediaPipe for hand landmark detection and scikit-learn for training a gesture recognition model.

ğŸ“¸ What it does:
Captures hand landmarks from webcam input using MediaPipe

Trains a Random Forest Classifier to recognize ASL letters

Classifies gestures in real-time with a visual bounding box and label overlay

ğŸ› ï¸ Tools & Technologies (Backend):
Python

OpenCV

MediaPipe

Scikit-learn

NumPy

Matplotlib (for visualizations)

ğŸ› ï¸ Tools & Technologies (Frontend):
React

React-webcam

Axios

HTML5 & CSS3

Vercel 

ğŸ“ Features:
Dataset collection via webcam

Landmark-based feature extraction

Custom model training & evaluation

Real-time sign prediction with video feedback
